{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical arrays\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical functions\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# One-way ANOVA\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks 1-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Permutations and Combinations\n",
    "\n",
    "In the Lady Tasting Tea experiment, we have twelve cups of tea: six with milk poured first and six with tea poured first. A person claims they can distinguish the order by taste. To test this, we ask them to identify which six cups had milk poured first.<br>\n",
    "### 1.1. Calculate the probability that they correctly identify all six cups by random guessing, assuming they have no special ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions of the experiment:\n",
    "\n",
    "total_cups = 12\n",
    "with_milk_first = 6\n",
    "with_tea_first = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the number of ways to choose six cups with milk poured first out of twelve cups can be done using **the choose function** formula.\n",
    "\n",
    "Where:<br>\n",
    "**n** = total_cups<br>\n",
    "**k** = with_milk_first<br>\n",
    "\n",
    "**number_of_ways = math.factorial(n) // (math.factorial(k) * math.factorial(n - k))**<br>\n",
    "\n",
    "[Python math.comb() Method](https://www.w3schools.com/python/ref_math_comb.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function **math.comb** in Python is the choose function and calculates all the possible ways to choose k from n. \n",
    "# The order does not matter and the elements can't be selected twice.\n",
    "total_comb = math.comb(total_cups,with_milk_first)\n",
    "total_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that there are 924 ways to choose 6 cups out of 12. We agreed, that the order doesn't matter, so there are only 1 way to choose all the cups with milk first. A person have no special powers and selection is just gessing.\n",
    "Now we can calculate the probability that they selects the six correct cups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating probability:\n",
    "prob = 1/total_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cup labels:\n",
    "labels = ['a','b','c','d','e','f','g','h','i','j','k','l']\n",
    "len(labels)\n",
    "#labels = list(range(total_cups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref.: [Python – Itertools Combinations() function\n",
    "](https://www.geeksforgeeks.org/python-itertools-combinations-function/) <br>\n",
    "\n",
    "**itertools.combinations()** generates all possible tuples from a given sequence or set of elements, treating each element as unique based on its position in the sequence.<br>\n",
    "We use it to generate all the ways six labeled cups might be choosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list combs will keep possible combinations of six cups out of our list \"labels\":\n",
    "combs = list(itertools.combinations(labels,with_milk_first))\n",
    "\n",
    "# Show 10 out of 924\n",
    "display(f'First 10 sets out of 924 possible options {combs[0:10]}')\n",
    "\n",
    "print(f'Number of combinations {len(combs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we choose six random cups to put milk in first:\n",
    "labels_with_milk = random.sample(labels,6)\n",
    "labels_with_milk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List contain elements in a particular order, but we agreed that the order doesn't matter. We turn labels_with_milk into a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_with_milk_first = set(labels_with_milk)\n",
    "set_with_milk_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref.: [Python Set intersection() Method](https://www.w3schools.com/python/ref_set_intersection.asp)<br>\n",
    "Now, when we know what cups are with milk first, we can check how many cups will be named correctly in each possible way to choose them. \n",
    "The **intersection()** method returns a set that contains the similarity between two or more sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the list we will write the number of correctly guessed cups with milk in first in each of the possible sets.\n",
    "no_correct_guesses = []\n",
    "\n",
    "for comb in combs:\n",
    "    #turn comb into a set:\n",
    "    s1 =set(comb)\n",
    "    s2 = set_with_milk_first\n",
    "    \n",
    "    #Checking if there are any overlaps\n",
    "    overlap = s1.intersection(s2)\n",
    "    \n",
    "    # we need only a number of overlaps, so we do append of len(overlap) to the no_correct_guesses\n",
    "    no_correct_guesses.append(len(overlap))\n",
    "    #print(comb, overlap, len(overlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref.: [numpy.unique](https://numpy.org/devdocs/reference/generated/numpy.unique.html)<br>\n",
    "We got the list of numbers of correctly named cups with milk in first. The maximum correct guesses in each set is six, and the minimum is zero. We want to figure out how many times all possible overlaps occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(no_correct_guesses, return_counts=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 2 arrays. One with possible overlaps and another with it's frequency.<br>\n",
    "\n",
    "There is **one** way to choose all the cups **with tee in first** and **one** way to choose all the cups **with milk in first.**<br>\n",
    "\n",
    "**One** cup with milk in first might be found in **thirty six sets**, as well as **five** cups with milk in first.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fig = figsize=(10, 6)\n",
    "sns.barplot(x=counts[0], y=counts[1], hue= counts[1])\n",
    "plt.title('Frequency on possible overlaps')\n",
    "plt.xlabel('number of correctly guessed cups')\n",
    "plt.ylabel('number of ways to choose it')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the barchart, for a person with no special power, there are more chanses to guess 3 cups with milk first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One error. Calculate the probability that they identify **at least five of the six** correct cups by random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I whant to determine the probability of guessing six cups with **one error**. That means that they must choose either **five** cups with milk in first out of **six**, or **6** cups with milk in first.  In this case I will calculate all the events together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the possible correct ways with one error and without an error:\n",
    "correct_one = (36+1)\n",
    "\n",
    "# all the possible ways to choose 6 cups\n",
    "total_comb\n",
    "\n",
    "prob_one_error = correct_one/total_comb\n",
    "print(f'The probability to pick at least five cups correctly is {round(prob_one_error,3)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Are two errors acceptable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to sum all events with one error, with two and without an error\n",
    "correct_two = (1 + 36 + 225)\n",
    "\n",
    "# all possible ways to celect 6 cups\n",
    "total_comb\n",
    "\n",
    "prob_two_errors = correct_two/total_comb\n",
    "print(f'The probability to pick at least four cups correctly is {(round(prob_two_errors,3)*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing a statistical test, we must decide on an acceptable significance level. Besides, two errors and four errors are equally likely, according to the barchart. If two errors are allowed, this increases the probability of a Type I error — where the null hypothesis is true, but we mistakenly reject it.  In this case, the null hypothesis is: \"The person is selecting the cups randomly and does not have the ability to distinguish the cups with milk in first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: numpy's Normal Distribution\n",
    "### 2.1.Generate Sample Data:\n",
    "Use **numpy.random.normal()** to generate a sample of 100,000 values.\n",
    "Set the mean to 10.0 and the standard deviation to 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref.:<br> [numpy.random.normal](https://numpy.org/doc/2.0/reference/random/generated/numpy.random.normal.html#numpy-random-normal)\n",
    "\n",
    "random.normal(loc=0.0, scale=1.0, size=None)<br>\n",
    "\n",
    "loc : Mean (“centre”) of the distribution.<br>\n",
    "scale: Standard deviation (spread or “width”) of the distribution.<br>\n",
    "size: Output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "mean=10.0\n",
    "\n",
    "#standard deviation \n",
    "std=3.0\n",
    "\n",
    "#sample size\n",
    "size=100000\n",
    "\n",
    "#Seed for repeating the results\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "sample = np.random.normal(mean,std,size)\n",
    "#sample[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.Test for Normality:\n",
    "Use the **scipy.stats.shapiro()** function to assess whether the generated sample is normally distributed.\n",
    "Interpret and explain the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref.:<br>[Shapiro-Wilk test](https://www.geeksforgeeks.org/how-to-perform-a-shapiro-wilk-test-in-python/)<br>\n",
    "[Alpha level](https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/what-is-an-alpha-level/)<br>\n",
    "\n",
    "**Shapiro-Wilk test** is a test of normality, it determines whether the given sample comes from the normal distribution or not. \n",
    "\n",
    "**Null hypothesis**: the random variable in the sample is normally distributed.<br>\n",
    "**Alternative Hypothesis**: The random variable in the sample is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Setting Alpha level**\n",
    "\n",
    "The significance level or alpha level is the probability of making the wrong decision when the null hypothesis is true (Type I error).\n",
    "\n",
    "We set alpha = 0.05, which means that the probability of making a Type I error is 5%.\n",
    "\n",
    "If **p-value < alpha**, we would reject the null hypothesis, indicating the data likely does not follow a normal distribution.\n",
    "\n",
    "If **p-value > alpha**, we fail to reject the null hypothesis. This means we do not have enough evidence to say the sample data doesn't come from the normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# function for performing the Shapiro-Wilk Test\n",
    "\n",
    "def test(data_sample, sanificanse_level):\n",
    "    result = shapiro(data_sample)\n",
    "    \n",
    "    if result[1] > alpha:\n",
    "        print(\n",
    "            f'We did not get enough evidence to reject The Null Hypothysis \\nthat the random variable in the sample is normally distributed. P-Value = {round(result[1],2)}'\n",
    "        )\n",
    "    else:\n",
    "        print(f'There is no evedense to accept The Null Hypothysis. P-Value = {round(result[1],2)}'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the function with our sample:\n",
    "test(sample,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test was performed, and the results indicate that our sample data is consistent with a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3. Visualize the Data:\n",
    "Plot a histogram of your values and plot the corresponding normal distribution probability density function on top of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating probability density function we need to find minimal and maximun x value, a size of sample and corresponding y values\n",
    "\n",
    "Ref.: [How to Plot Normal Distribution over Histogram in Python](https://www.geeksforgeeks.org/how-to-plot-normal-distribution-over-histogram-in-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "fig,ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(sample, density=True,color='darkgreen',edgecolor='black',alpha=0.4)\n",
    "# density=True is a parameter for normalization.\n",
    "# The hist is normalized so that the area under the histogram integrates to 1.\n",
    "\n",
    "ax.set_title(\"Normal Distribution\")\n",
    "ax.set_xlabel(\"Value\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "#Probability Density Function parameters:\n",
    "min_x = sample.min() #minimal x value \n",
    "max_x = sample.max() #maximal x value \n",
    "x = np.linspace(min_x, max_x, len(sample))\n",
    "y = stats.norm.pdf(x, mean, std) # geting y values\n",
    "\n",
    "#Plot\n",
    "ax.plot(x,y,'r-', label='PDF', linewidth=2)\n",
    "ax.annotate(xytext=[15, 0.12], text='Probability Density Function', xy=[11.5,0.12], arrowprops={'arrowstyle': '->', 'color': 'black'})\n",
    "\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: t-Test Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1. Consider the dataset containing resting heart rates for patients before and after embarking on a two-week exercise program.\n",
    "\n",
    "I have [data](https://github.com/ianmcloughlin/2425_applied_statistics?tab=readme-ov-file) here, and I want to create 2 arrays from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two arrays with data representing hartrates of patients\n",
    "# before and after two-week exercise program.\n",
    "\n",
    "heartrate_before = np.array([63,68,70,64,74,67,70,57,66,65])\n",
    "heartrate_after = np.array([64,64,68,64,73,70,72,54,61,63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pandas DataFrame\n",
    "hartrate_df = pd.DataFrame({\n",
    "    'heartrate_before': heartrate_before,\n",
    "    'heartrate_after': heartrate_after\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. Assumptions.\n",
    "* Assumption #1: The dependent variable, **heart rate**, is measured on a continuous scale (interval data).<br>\n",
    "* Assumption #2: The independent variable consists of two related groups: heart rates measured **before** and **after** the two-week exercise program.<br>\n",
    "* Assumption #3: The differences between paired observations (heart rate before and after) should not have significant outliers.(Check with box plot)<br>\n",
    "* Assumption #4: The distribution of the differences in heart rates between the two groups should be approximately normally distributed.(Check with Q-Q plot or Sapiro-Wilk test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box-and-whisker plot to visualize the distribution of heart rate data\n",
    "# and identify potential outliers for both the \"Before\" and \"After\" conditions.\n",
    "sns.catplot(hartrate_df, kind='box', height=6)\n",
    "plt.title(\"Distribution of Heart Rate Data: Before and After\")\n",
    "plt.xlabel(\"Condition\", fontsize=12)\n",
    "plt.ylabel(\"Heart Rate\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapiro-Wilk test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform the Shapiro-Wilk test I will use the function from Task #2:\n",
    "\n",
    "# Checking thae data with heart rate before the program:\n",
    "alpha=0.05\n",
    "test(heartrate_before,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking thae data with heart rate after the program:\n",
    "alpha=0.05\n",
    "test(heartrate_after,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the ststistics in both groups:\n",
    "hartrate_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean heart rate for the 'heartrate_before' group is 66.4, while for the 'heartrate_after' group, it is 65.3. To determine whether this difference is statistically significant, a paired t-test can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.Paired Samples $t$-Test\n",
    "#### Calculate the t-statistic based on this data set, using Python. Compare it to the value given by scipy.stats. Explain your work and list any sources used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means of these groups are quite similar. I will use a t-test to compare the means and determine if the observed difference is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Types of $t$-Test](https://datatab.net/tutorial/t-test)<br>\n",
    "[$t$-tests in Python](https://www.datacamp.com/tutorial/an-introduction-to-python-t-tests?utm_source=google&utm_medium=paid_search&utm_campaignid=19589720824&utm_adgroupid=157156376311&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=720362650453&utm_targetid=dsa-2218886984100&utm_loc_interest_ms=&utm_loc_physical_ms=1007890&utm_content=&utm_campaign=230119_1-sea~dsa~tofu_2-b2c_3-row-p2_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na-bfcm24&gad_source=1&gclid=Cj0KCQiAi_G5BhDXARIsAN5SX7pQ0aY0QXyd2Ix2RLW2lQYol1FE9E3dYWeKhhA_uoVpgOi7zTYLsmYaAnkIEALw_wcB)\n",
    "\n",
    "**The $t$-Test** is a statistical test procedure that tests whether there is a significant difference between the means of two groups.\n",
    "\n",
    "* One-Sample $t$-Test: Compares the mean of one group to a known value.\n",
    "* Independent Samples $t$-Test: Compares the means of two independent groups.\n",
    "* Paired Samples $t$-Test: Compares the means of two related groups (e.g., before-and-after).\n",
    "\n",
    "If assumptions like normal distribution or equal variances are not met, non-parametric alternatives like the Mann-Whitney U test or Wilcoxon test may be used​.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a Paired Samples $t$-Test I use the [ttest_rel](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) function from the scipy.stats module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Hypotheses.\n",
    "\n",
    "**Null Hypothesis:**\n",
    "There is no significant difference in the average heart rates of patients before and after the two-week exercise program.<br>\n",
    "\n",
    "**Alternative Hypothesis:**\n",
    "There is a significant difference in the average heart rates of patients before and after the two-week exercise program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Significance level.\n",
    "[Significance level](https://statisticsbyjim.com/glossary/significance-level/)<br>\n",
    "\n",
    "The significance level is the probability of rejecting the null hypothesis when it is true. A significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference.\n",
    "\n",
    "If the **p-value** is less than significance level, the null hypothesis will be rejected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a sagnificance level\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. $t$-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two samples\n",
    "x = heartrate_before\n",
    "y = heartrate_after\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Function for paired t-test:\n",
    "def paired_ttest(first_sample,second_sample,signif_lv):\n",
    "\n",
    "    t_stat, p_val = stats.ttest_rel(x,y)\n",
    "\n",
    "    print(\"t-statistic = \" + str(t_stat))  \n",
    "    print(\"p-value = \" + str(p_val))\n",
    "    print(\"------------------------\") \n",
    "\n",
    "    if p_val <= alpha:\n",
    "        print('There might be a statistical difference between the two samples.')\n",
    "    else:\n",
    "        print('There is no evidence that the difference\\nbetween the samples is statistically significant.')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the function\n",
    "paired_ttest(x,y,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4. Interpretation of the test results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t-statistic:** measures the size of the difference between the samples.\n",
    "\n",
    "**p-value**: indicates whether the observed difference is statistically significant.\n",
    "\n",
    "**alpha**: The significance level (commonly set to 0.05), meaning that if the p-value is less than or equal to 0.05, the difference is considered statistically significant.\n",
    "\n",
    "Since the p-value (0.2139) is greater than the significance level (0.05), **there is no evidence to suggest a statistically significant difference in heart rates before and after the two-week exercise program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. ANOVA\n",
    "Estimate the probability of committing a type II error in specific circumstances. To begin, create a variable called no_type_ii and set it to 0.\n",
    "Now use a loop to perform the following test 10,000 times.\n",
    "Use numpy.random.normal to generate three samples with 100 values each.<br> Give each a standard deviation of 0.1.<br> Give the first sample a mean of 4.9, the second a mean of 5.0, and the third a mean of 5.1.<br>\n",
    "Perform one-way ANOVA on the three samples and add 1 to no_type_ii whenever a type II error occurs.\n",
    "Summarize and explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Type II error**, or a false negative, occurs when the null hypothesis is not rejected, even though it is actually false.\n",
    "\n",
    "*Null Hypothesis*: There is no significant statistical difference between the samples.\n",
    "*Alternative Hypothesis*: There is a significant statistical difference between the samples.\n",
    "\n",
    "If the p-value < 0.05, we reject the null hypothesis (The difference is possible).\n",
    "\n",
    "In the given case a Type II error may happen when the p-value > 0.05, so we don’t reject the null hypothesis, even though it’s actually false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The counter for errors, when p-value > 0.05\n",
    "no_type_ii = 0\n",
    "\n",
    "# The counter for p-value < 0.05\n",
    "p_v_less = 0 \n",
    "\n",
    "# The counter for p-value > 0.05\n",
    "p_v_more = 0\n",
    "\n",
    "# How many times the test performed\n",
    "n = 10000\n",
    "\n",
    "# Generating three samples\n",
    "for _ in range (n):   \n",
    "    sample_a = np.random.normal(loc=4.9, scale=0.1,size=100)\n",
    "    sample_b = np.random.normal(loc=5.0, scale=0.1,size=100)\n",
    "    sample_c = np.random.normal(loc=5.1, scale=0.1,size=100)  \n",
    "    \n",
    "# Performing the One-way ANOVA\n",
    "    statistic, p_value = f_oneway(sample_a, sample_b, sample_c)\n",
    "    if p_value > 0.05:\n",
    "        p_v_more += 1\n",
    "        no_type_ii +=1\n",
    "    else:\n",
    "        p_v_less += 1\n",
    "print(f'No difference: {p_v_more} times. The samples are different: {p_v_less} times.')\n",
    "print(f'The type II error was obrerved {no_type_ii} times out of {n} trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The test was run many times with the given parameters, and no Type II errors were found, showing the test could detect small differences between the samples. However, when the means of the samples were made the same, a Type I error happened in 3-10% of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
